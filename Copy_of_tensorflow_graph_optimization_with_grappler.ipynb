{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tensorflow graph optimization with grappler.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavansai26/TENSORFLOW-GRAPH-OPTIMIZATION-WITH-GRAPPLER/blob/master/Copy_of_tensorflow_graph_optimization_with_grappler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vPjkrNMw88P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3MPf91rVYesq"
      },
      "source": [
        "# Part 1. TensorFlow graph optimization with Grappler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WZAUsxyWYess"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6BRIDzO6ypoY",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "import traceback\n",
        "import contextlib\n",
        "\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1O-XL1nxJX0X"
      },
      "source": [
        "Create a context manager to easily toggle optimizer states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uRuhVoAlYesz",
        "colab": {}
      },
      "source": [
        "@contextlib.contextmanager\n",
        "def options(options):\n",
        "  old_opts = tf.config.optimizer.get_experimental_options()\n",
        "  tf.config.optimizer.set_experimental_options(options)\n",
        "  try:\n",
        "    yield\n",
        "  finally:\n",
        "    tf.config.optimizer.set_experimental_options(old_opts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E2o4kZtK0DoA"
      },
      "source": [
        "## Compare execution performance with and without Grappler\n",
        "\n",
        "TensorFlow 2 and beyond executes [eagerly](../eager.md) by default. Use `tf.function` to switch the default execution to Graph mode. Grappler runs automatically in the background to apply the graph optimizations above and improve execution performance. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_epHfOQxBmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_function_1():\n",
        "  @tf.function\n",
        "  def simple_function(input_arg):\n",
        "    print('Tracing!')\n",
        "    a = tf.constant(np.random.randn(2000,2000), dtype = tf.float32)\n",
        "    c = a\n",
        "    for n in range(50):\n",
        "      c = c@a\n",
        "    return tf.reduce_mean(c+input_arg)\n",
        "\n",
        "  return simple_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFVgUhhzLKIo"
      },
      "source": [
        "Turn off the constant folding optimizer and execute the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TVZLK_DxKJ_",
        "colab_type": "code",
        "outputId": "85ce78c3-8f86-4d72-d247-4b3b0a4295fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "with options({'constant_folding': False}):\n",
        "  print(tf.config.optimizer.get_experimental_options())\n",
        "  simple_function = test_function_1()\n",
        "  # Trace once\n",
        "  x = tf.constant(2.2)\n",
        "  simple_function(x)\n",
        "  print(\"Vanilla execution:\", timeit.timeit(lambda: simple_function(x), number = 1), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'constant_folding': False, 'debug_stripper': True, 'disable_model_pruning': False, 'disable_meta_optimizer': False}\n",
            "Tracing!\n",
            "Vanilla execution: 12.63284338000085 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ykMXfo8qO41z"
      },
      "source": [
        "Enable the constant folding optimizer and execute the function again to observe a speed-up in function execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTsFnIcrxKHq",
        "colab_type": "code",
        "outputId": "1dadb827-5ad1-4d1b-efa0-b8dc9c62837e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "with options({'constant_folding': True}):\n",
        "  print(tf.config.optimizer.get_experimental_options())\n",
        "  simple_function = test_function_1()\n",
        "  # Trace once\n",
        "  x = tf.constant(2.2)\n",
        "  simple_function(x)\n",
        "  print(\"Constant folded execution:\", timeit.timeit(lambda: simple_function(x), number = 1), \"s\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'constant_folding': True, 'debug_stripper': True, 'disable_model_pruning': False, 'disable_meta_optimizer': False}\n",
            "Tracing!\n",
            "Constant folded execution: 0.004807434999747784 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "83w8rfcRVhWb"
      },
      "source": [
        "### Debug stripper optimizer\n",
        "\n",
        "Consider a simple function that checks the numeric value of its input argument and returns it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFtq1xA8xecv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_function_2():\n",
        "  @tf.function\n",
        "  def simple_func(input_arg):\n",
        "    output = input_arg\n",
        "    tf.debugging.check_numerics(output, \"Bad!\")\n",
        "    return output\n",
        "  return simple_func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ywKG3WRbpYB8"
      },
      "source": [
        "First, execute the function with the debug stripper optimizer turned off. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo_kb7RMxnmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_func = test_function_2()\n",
        "p1 = tf.constant(float('inf'))\n",
        "try:\n",
        "  test_func(p1)\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  traceback.print_exc(limit=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CuPSha9YmJRo"
      },
      "source": [
        "Enable the debug stripper optimizer and execute the function again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H36FOsJrxnpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with options({'debug_stripper': True}):\n",
        "  test_func2 = test_function_2()\n",
        "  p1 = tf.constant(float('inf'))\n",
        "  try:\n",
        "    test_func2(p1)\n",
        "  except tf.errors.InvalidArgumentError as e:\n",
        "    traceback.print_exc(limit=2)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wHC6tR9GvFgW"
      },
      "source": [
        "## Summary\n",
        "\n",
        "The TensorFlow runtime uses Grappler to optimize graphs automatically before execution. Use `tf.config.optimizer.set_experimental_options` to enable or disable the various graph optimizers. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCyK_X6Lxymw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhpnXAhxxykr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1oSi4lHFt3z"
      },
      "source": [
        "# Part 2. Using XLA with Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sDy5lSBd4BDE"
      },
      "source": [
        "This part trains a TensorFlow model to classify the MNIST dataset, where the training function is compiled using XLA.\n",
        "\n",
        "First, load TensorFlow and enable eager execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaCNf9_JxnAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GZVNiRmTDV-5"
      },
      "source": [
        "Then define some necessary constants and prepare the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4msvPOhxJSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Size of each input image, 28 x 28 pixels\n",
        "IMAGE_SIZE = 28 * 28\n",
        "# Number of distinct number labels, [0..9]\n",
        "NUM_CLASSES = 10\n",
        "# Number of examples in each training batch (step)\n",
        "TRAIN_BATCH_SIZE = 100\n",
        "# Number of training steps to run\n",
        "TRAIN_STEPS = 1000\n",
        "\n",
        "# Loads MNIST dataset.\n",
        "train, test = tf.keras.datasets.mnist.load_data()\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(train).batch(TRAIN_BATCH_SIZE).repeat()\n",
        "\n",
        "# Casting from raw data to the required datatypes.\n",
        "def cast(images, labels):\n",
        "  images = tf.cast(\n",
        "      tf.reshape(images, [-1, IMAGE_SIZE]), tf.float32)\n",
        "  labels = tf.cast(labels, tf.int64)\n",
        "  return (images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lv7I-u_82v1S"
      },
      "source": [
        "Finally, define the model and the optimizer. The model uses a single dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io8plzwF9eI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer = tf.keras.layers.Dense(NUM_CLASSES)\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x_ZehpZP-SfS"
      },
      "source": [
        "# Define the training function\n",
        "\n",
        "In the training function, you get the predicted labels using the layer defined above, and then minimize the gradient of the loss using the optimizer. In order to compile the computation using XLA, place it inside `tf.function` with `experimental_compile=True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7cg2eVt9eGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function(experimental_compile=True)\n",
        "def train_mnist(images, labels):\n",
        "    images, labels = cast(images, labels)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted_labels = layer(images)\n",
        "      loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          logits=predicted_labels, labels=labels\n",
        "      ))\n",
        "    layer_variables = layer.trainable_variables\n",
        "    grads = tape.gradient(loss, layer_variables)\n",
        "    optimizer.apply_gradients(zip(grads, layer_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EZD1m_n1DxAF"
      },
      "source": [
        "# Train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrXbFR2j-bBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in train_ds:\n",
        "  if optimizer.iterations > TRAIN_STEPS:\n",
        "    break\n",
        "  train_mnist(images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCaChOl6-bRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = cast(test[0], test[1])\n",
        "predicted_labels = layer(images)\n",
        "correct_prediction = tf.equal(tf.argmax(predicted_labels, 1), labels)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Prediction accuracy after training: %s\" % accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjofGbpv-lh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKtAyQYj-lk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}